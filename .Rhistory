"Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel"),
y=y,
model=svm,
train=training,
test=test,
type="classification",
params=list(kernel="raidal basis",
cost=1,
type="C-classification"))
)
i = 0
for(i in 1:length(params)) {
id <- paste("params", i, sep="")
print(id)
#
model_results <- do.call(model_trainer, params[[id]])
# model_results <- model_trainer(xs=params[[id]]$xs,
#                                y=params[[id]]$y,
#                                train=train,
#                                test=test,
#                                model=params[[id]]$model,
#                                type=params[[id]]$type
# )
models[[id]] <- model_results
}
best_acc <- 0
best_model <- NULL
for (model in models){
cat("Accuracy: ", model$score, "\n")
if (model$score > best_acc){
best_model <- model$model
save(best_model, "./models/best_svm.rda")
}
}
## SVM modeling
source("./ModelingFuncs.R")
source("./DataCleaning.R")
library(readxl)
library(caTools)
library(e1071)
# read the data file in as a dataframe
model_data <- read_xlsx("./data/Satisfaction Survey(2).xlsx")
model_data <- process_flight_survey(model_data)
sapply(model_data, function(x) sum(is.na(x)))
y = "Satisfaction"
usable_x_cols <- c("Gender", "Price_Sensitivity", "Shopping_Amount_at_Airport",
"Day_of_Month", "Scheduled_Departure_Hour",
"Flight_cancelled", "Flight_time_in_minutes", "Flight_Distance",
"Airline_StatusGold", "Airline_StatusPlatinum"  ,
"Airline_StatusSilver", "Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel",
"ClassEco", "ClassEco.Plus", "cat_loyalty_cards.Low",
"cat_loyalty_cards.Medium", "cat_loyalty_cards.High", "cat_No_of_Flights.Medium",
"cat_No_of_Flights.High", "cat_Age..20.30.", "cat_Age..30.40.",
"cat_Age..40.50.", "cat_Age..50.60.", "cat_Age..60.70.",
"cat_Age..70..Inf.", "X.cat_._of_FLight_with_other.Medium", "X.cat_._of_FLight_with_other.High", "Age")
# set the seed so we can compare our results on the same splits
set.seed(11)
#########################################
# Support Vector Machine Model Training
########################################
# Clean up and scale some of the columns
model_data$Satisfaction <- as.numeric(factor(model_data$Satisfaction,
levels=c(1.0, 2.0, 2.5, 3.0, 3.4, 3.5, 4.0, 4.5, 5.0),
labels=c(1, 2, 3, 4, 5, 6, 7, 8, 9)))
model_data$Gender <- as.numeric(factor(model_data$Gender,
levels=c("Male", "Female"),
labels=c(0, 1)))
model_data$Flight_cancelled <- as.numeric(factor(model_data$Flight_cancelled,
levels=c("No", "Yes"),
labels=c(0, 1)))
scale_cols <- c("Shopping_Amount_at_Airport",
"Flight_time_in_minutes",
"Flight_Distance", "No_of_Flights_p.a.", "Eating_and_Drinking_at_Airport",
"Departure_Delay_in_Minutes", "Arrival_Delay_in_Minutes")
for (col in scale_cols){
print(col)
model_data[, col] <- scale(model_data[,col])
}
# split the data into training and test data
split = sample.split(model_data$Satisfaction, SplitRatio=.8)
training = subset(model_data, split == TRUE)
test = subset(model_data, split == FALSE)
str(training)
models <- list()
params <- list(params1=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes",
"Flight_Distance",
"Scheduled_Departure_Hour", "Day_of_Month"),
y=y,
model=svm,
train=training,
test=test,
type="classification",
params=list(kernel="raidal basis",
cost=10,
type="C-classification")),
params2=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes", "Eating_and_Drinking_at_Airport",
"No_of_Flights_p.a.","Departure_Delay_in_Minutes"),
y=y,
model=svm,
type="classification",
train=training,
test=test,
params=list(kernel="raidal basis",
cost=5,
type="C-classification")),
params3=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes",
"Flight_Distance",
"Scheduled_Departure_Hour", "Day_of_Month",
"Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel"),
y=y,
model=svm,
train=training,
test=test,
type="classification",
params=list(kernel="raidal basis",
cost=3,
type="C-classification")),
params4=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes",
"Flight_Distance",
"Scheduled_Departure_Hour", "Day_of_Month",
"Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel"),
y=y,
model=svm,
train=training,
test=test,
type="classification",
params=list(kernel="raidal basis",
cost=1,
type="C-classification"))
)
i = 0
for(i in 1:length(params)) {
id <- paste("params", i, sep="")
print(id)
#
model_results <- do.call(model_trainer, params[[id]])
# model_results <- model_trainer(xs=params[[id]]$xs,
#                                y=params[[id]]$y,
#                                train=train,
#                                test=test,
#                                model=params[[id]]$model,
#                                type=params[[id]]$type
# )
models[[id]] <- model_results
}
best_acc <- 0
best_model <- NULL
for (model in models){
cat("Accuracy: ", model$score, "\n")
if (model$score > best_acc){
best_model <- model$model
save(best_model, "./models/best_svm.rda")
}
}
source('~/Syracuse/IST687-IntroDataScience/FlightSurveyProject/ClassificationModeling.R', echo=TRUE)
source("./ModelingFuncs.R")
source("./DataCleaning.R")
library(readxl)
library(caTools)
library(e1071)
# read the data file in as a dataframe
model_data <- read_xlsx("./data/Satisfaction Survey(2).xlsx")
model_data <- process_flight_survey(model_data)
sapply(model_data, function(x) sum(is.na(x)))
y = "Satisfaction"
usable_x_cols <- c("Gender", "Price_Sensitivity", "Shopping_Amount_at_Airport",
"Day_of_Month", "Scheduled_Departure_Hour",
"Flight_cancelled", "Flight_time_in_minutes", "Flight_Distance",
"Airline_StatusGold", "Airline_StatusPlatinum"  ,
"Airline_StatusSilver", "Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel",
"ClassEco", "ClassEco.Plus", "cat_loyalty_cards.Low",
"cat_loyalty_cards.Medium", "cat_loyalty_cards.High", "cat_No_of_Flights.Medium",
"cat_No_of_Flights.High", "cat_Age..20.30.", "cat_Age..30.40.",
"cat_Age..40.50.", "cat_Age..50.60.", "cat_Age..60.70.",
"cat_Age..70..Inf.", "X.cat_._of_FLight_with_other.Medium", "X.cat_._of_FLight_with_other.High", "Age")
# set the seed so we can compare our results on the same splits
set.seed(11)
#########################################
# Classification Models
########################################
# split the data into training and test data
model_data$Satisfaction <- as.factor(model_data$Satisfaction)
split = sample.split(model_data$Satisfaction, SplitRatio=.8)
training = subset(model_data, split == TRUE)
test = subset(model_data, split == FALSE)
library(e1071)
params <- list(params1=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes"),
y=y,
model=naiveBayes,
train=training, test=test,
type="classification",
params=list(laplace=1)),
params2=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes"),
y=y,
model=naiveBayes,
train=training, test=test,
type="classification",
params=list(laplace=.5)),
params3=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes", "DepDelayRatio", "ArrDelayRatio",
"Airline_StatusGold", "Airline_StatusPlatinum",
"Airline_StatusSilver"),
y=y,
model=naiveBayes,
train=training, test=test,
type="classification",
params=list(laplace=.5)),
params4=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes", "DepDelayRatio",
"Airline_Status", "Type_of_Travel"),
y=y,
model=naiveBayes,
train=training, test=test,
type="classification",
params=list(laplace=1)),
params5=list(xs=c("Gender", "Price_Sensitivity", "Age",
"Shopping_Amount_at_Airport", "Flight_cancelled",
"Flight_time_in_minutes", "DepDelayRatio",
"Airline_Status", "Type_of_Travel", "Scheduled_Departure_Hour",
"Shopping_Amount_at_Airport", "Day_of_Month"),
y=y,
model=naiveBayes,
train=training, test=test,
type="classification",
params=list())
)
i = 0
for(i in 1:length(params)) {
id <- paste("params", i, sep="")
print(id)
#
model_results <- do.call(model_trainer, params[[id]])
# model_results <- model_trainer(xs=params[[id]]$xs,
#                                y=params[[id]]$y,
#                                train=train,
#                                test=test,
#                                model=params[[id]]$model,
#                                type=params[[id]]$type
#                                )
models[[id]] <- model_results
}
for (model in models){
cat("Accuracy: ", model$score, "\n")
}
## SVM modeling
source("./ModelingFuncs.R")
source("./DataCleaning.R")
library(readxl)
library(caTools)
library(e1071)
# read the data file in as a dataframe
model_data <- read_xlsx("./data/Satisfaction Survey(2).xlsx")
model_data <- process_flight_survey(model_data)
sapply(model_data, function(x) sum(is.na(x)))
y = "Satisfaction"
usable_x_cols <- c("Gender", "Price_Sensitivity", "Shopping_Amount_at_Airport",
"Day_of_Month", "Scheduled_Departure_Hour",
"Flight_cancelled", "Flight_time_in_minutes", "Flight_Distance",
"Airline_StatusGold", "Airline_StatusPlatinum"  ,
"Airline_StatusSilver", "Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel",
"ClassEco", "ClassEco.Plus", "cat_loyalty_cards.Low",
"cat_loyalty_cards.Medium", "cat_loyalty_cards.High", "cat_No_of_Flights.Medium",
"cat_No_of_Flights.High", "cat_Age..20.30.", "cat_Age..30.40.",
"cat_Age..40.50.", "cat_Age..50.60.", "cat_Age..60.70.",
"cat_Age..70..Inf.", "X.cat_._of_FLight_with_other.Medium", "X.cat_._of_FLight_with_other.High", "Age")
# set the seed so we can compare our results on the same splits
set.seed(11)
#########################################
# Support Vector Machine Model Training
########################################
# Clean up and scale some of the columns
model_data$Satisfaction <- as.numeric(factor(model_data$Satisfaction,
levels=c(1.0, 2.0, 2.5, 3.0, 3.4, 3.5, 4.0, 4.5, 5.0),
labels=c(1, 2, 3, 4, 5, 6, 7, 8, 9)))
model_data$Gender <- as.numeric(factor(model_data$Gender,
levels=c("Male", "Female"),
labels=c(0, 1)))
model_data$Flight_cancelled <- as.numeric(factor(model_data$Flight_cancelled,
levels=c("No", "Yes"),
labels=c(0, 1)))
scale_cols <- c("Shopping_Amount_at_Airport",
"Flight_time_in_minutes",
"Flight_Distance", "No_of_Flights_p.a.", "Eating_and_Drinking_at_Airport",
"Departure_Delay_in_Minutes", "Arrival_Delay_in_Minutes")
for (col in scale_cols){
print(col)
model_data[, col] <- scale(model_data[,col])
}
# split the data into training and test data
split = sample.split(model_data$Satisfaction, SplitRatio=.8)
training = subset(model_data, split == TRUE)
test = subset(model_data, split == FALSE)
library(e1071)
svm2 <- load("./models/svm2.rda")
svm2_preds = predict(svm2, test)
svm2_acc = sum(test$Satisfaction == svm2_preds) / length(svm1_preds)
# svm2_probs <- predict(svm2, test)
svm2_results <- data.frame(test, predictions=svm2_preds)
svm2_results$result <- svm2_results$Satisfaction == svm2_results$predictions
table(svm2_results$Satisfaction, svm2_results$predictions)
library(ggplot2)
# library(plotROC)
# library(pROC)
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=result, shape=predictions)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=result, shape=predictions)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
load("./models/svm2.rda")
svm2_preds = predict(svm2, test)
svm2_acc = sum(test$Satisfaction == svm2_preds) / length(svm1_preds)
# svm2_probs <- predict(svm2, test)
svm2_results <- data.frame(test, predictions=svm2_preds)
svm2_results$result <- svm2_results$Satisfaction == svm2_results$predictions
table(svm2_results$Satisfaction, svm2_results$predictions)
library(ggplot2)
# library(plotROC)
# library(pROC)
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=result, shape=predictions)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=result, shape=predictions)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
svm2_acc = sum(test$Satisfaction == svm2_preds) / length(svm1_preds)
svm2_acc = sum(test$Satisfaction == svm2_preds) / length(svm2_preds)
svm2_results$result <- as.numeric(svm2_results$result)
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=result, shape=predictions)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=predictions, size=result)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
svm2_results$result <- !svm2_results$Satisfaction == svm2_results$predictions
svm2_results$result <- as.numeric(svm2_results$result)
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=predictions, size=result)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
svm2_results$result <- svm2_results$Satisfaction == svm2_results$predictions
svm2_results$result <- as.numeric(svm2_results$result)
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=predictions, shape=result)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
svm2_results$result <- svm2_results$Satisfaction == svm2_results$predictions
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=predictions, shape=result)) +
geom_point() +
ggtitle("SVM Predictions on Test Data")
ggsave("./images/SVM2_preds_Distance_Age.png")
source("./ModelingFuncs.R")
source("./DataCleaning.R")
library(readxl)
library(caTools)
library(e1071)
# read the data file in as a dataframe
model_data <- read_xlsx("./data/Satisfaction Survey(2).xlsx")
model_data <- process_flight_survey(model_data)
sapply(model_data, function(x) sum(is.na(x)))
y = "Satisfaction"
usable_x_cols <- c("Gender", "Price_Sensitivity", "Shopping_Amount_at_Airport",
"Day_of_Month", "Scheduled_Departure_Hour",
"Flight_cancelled", "Flight_time_in_minutes", "Flight_Distance",
"Airline_StatusGold", "Airline_StatusPlatinum"  ,
"Airline_StatusSilver", "Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel",
"ClassEco", "ClassEco.Plus", "cat_loyalty_cards.Low",
"cat_loyalty_cards.Medium", "cat_loyalty_cards.High", "cat_No_of_Flights.Medium",
"cat_No_of_Flights.High", "X.cat_._of_FLight_with_other.Medium",
"X.cat_._of_FLight_with_other.High", "Age", "DepDelayRatio", "No_of_Flights_p.a.")
# set the seed so we can compare our results on the same splits
set.seed(11)
# split the data into training and test data
unique(model_data$Satisfaction)
model_data$Satisfaction <- as.numeric(factor(model_data$Satisfaction,
levels=c(1.0, 2.0, 2.5, 3.0, 3.4, 3.5, 4.0, 4.5, 5.0),
labels=c(1, 2, 3, 4, 5, 6, 7, 8, 9)))
model_data$Satisfaction <- model_data$Satisfaction - 1
model_data$Type_of_Travel <- as.factor(model_data$Type_of_Travel)
model_data$Gender <- as.numeric(factor(model_data$Gender,
levels=c("Male", "Female"),
labels=c(0, 1)))
model_data$Flight_cancelled <- as.numeric(factor(model_data$Flight_cancelled,
levels=c("No", "Yes"),
labels=c(0, 1)))
split = sample.split(model_data$Satisfaction, SplitRatio=.8)
training = subset(model_data, split == TRUE)
test = subset(model_data, split == FALSE)
library(xgboost)
ggplot(svm2_results, aes(x=Age, y=Flight_Distance, color=predictions, shape=result)) +
geom_point() +
ggtitle(paste("SVM Predictions on Test Data - Accuracy: ", round(svm2_acc * 100, 2) ,"%", sep=""))
ggsave("./images/SVM2_preds_Distance_Age.png")
load("./models/classifier250tree.model")
load("./models/classifier500tree.model")
load("./models/classifier500tree_6depth.model")
load("./models/classifier1000tree_3depth.model")
load("./models/classifier1000tree_6depth_3eta.model")
load("./models/classifier2000tree_3depth_3eta.model")
xgb.load("./models/classifier250tree.model")
class1 <-xgb.load("./models/classifier250tree.model")
classifier <-xgb.load("./models/classifier250tree.model")
classifier <-xgb.load("./models/classifier250tree.model")
classifier2 <- xgb.load("./models/classifier500tree.model")
classifier3 <- xgb.load("./models/classifier500tree_6depth.model")
classifier4 <- xgb.load("./models/classifier1000tree_3depth.model")
classifier5 <- xgb.load("./models/classifier1000tree_6depth_3eta.model")
classifier6 <- xgb.load("./models/classifier2000tree_3depth_3eta.model")
preds6 <- predict(classifier6,
newdata=as.matrix(test[, usable_x_cols]))
merror6 = sum(!(test$Satisfaction == preds6)) / length(test$Satisfaction)
preds5 <- predict(classifier5,
newdata=as.matrix(test[, usable_x_cols]))
merror5 = sum(!(test$Satisfaction == preds5)) / length(test$Satisfaction)
preds4 <- predict(classifier4,
newdata=as.matrix(test[, usable_x_cols]))
merror4 = sum(!(test$Satisfaction == preds4)) / length(test$Satisfaction)
preds3 <- predict(classifier3,
newdata=as.matrix(test[, usable_x_cols]))
merror3 = sum(!(test$Satisfaction == preds3)) / length(test$Satisfaction)
preds2 <- predict(classifier2,
newdata=as.matrix(test[, usable_x_cols]))
merror2 = sum(!(test$Satisfaction == preds2)) / length(test$Satisfaction)
preds <- predict(classifier,
newdata=as.matrix(test[, usable_x_cols]))
merror = sum(!(test$Satisfaction == preds)) / length(test$Satisfaction)
## 7
classifier7 <- xgboost(params=list(objective="multi:softmax", "num_class"=9, "eval_metric"="merror", "max_depth"=3,
"eta"=0.1) ,
data=as.matrix(training[, usable_x_cols]),
label=training$Satisfaction, nrounds=5000,
verbose=1)
xgb.save(classifier7, "./models/classifier5000tree_3depth_1eta.model")
xgb.plot.importance(xgb.importance(usable_x_cols, model=classifier7))
preds7 <- predict(classifier7,
newdata=as.matrix(test[, usable_x_cols]))
merror7 = sum(!(test$Satisfaction == preds7)) / length(test$Satisfaction)
clss4_res <- data.frame(test[, usable_x_cols], preds=preds4)
clss4_res <- data.frame(test, preds=preds4)
class4_res <- data.frame(test, preds=preds4)
rm(clss4_res)
class4_res$result <- class4_res$Satisfaction == class4_res$preds
library(ggplot2)
ggplot(class4_res, aes(x=Age, y=Flight_Distance, color=preds, shape=result)) +
geom_point() +
ggtitle(paste("XGBoost Predictions on Test Data - Accuracy: ", round((1 - merror4) * 100, 2) ,"%", sep=""))
ggsave("./images/classifier4_preds_Distance_Age.png")
class4_res$preds <- as.factor(class4_res$preds)
ggplot(class4_res, aes(x=Age, y=Flight_Distance, color=preds, shape=result)) +
geom_point() +
ggtitle(paste("XGBoost Predictions on Test Data - Accuracy: ", round((1 - merror4) * 100, 2) ,"%", sep=""))
ggsave("./images/classifier4_preds_Distance_Age.png")
source("./ModelingFuncs.R")
source("./DataCleaning.R")
library(readxl)
library(caTools)
library(e1071)
# read the data file in as a dataframe
model_data <- read_xlsx("./data/Satisfaction Survey(2).xlsx")
model_data <- process_flight_survey(model_data)
sapply(model_data, function(x) sum(is.na(x)))
y = "Satisfaction"
usable_x_cols <- c("Gender", "Price_Sensitivity", "Shopping_Amount_at_Airport",
"Day_of_Month", "Scheduled_Departure_Hour",
"Flight_cancelled", "Flight_time_in_minutes", "Flight_Distance",
"Airline_StatusGold", "Airline_StatusPlatinum"  ,
"Airline_StatusSilver", "Type_of_TravelMileage.tickets", "Type_of_TravelPersonal.Travel",
"ClassEco", "ClassEco.Plus", "cat_loyalty_cards.Low",
"cat_loyalty_cards.Medium", "cat_loyalty_cards.High", "cat_No_of_Flights.Medium",
"cat_No_of_Flights.High", "cat_Age..20.30.", "cat_Age..30.40.",
"cat_Age..40.50.", "cat_Age..50.60.", "cat_Age..60.70.",
"cat_Age..70..Inf.", "X.cat_._of_FLight_with_other.Medium", "X.cat_._of_FLight_with_other.High", "Age")
# set the seed so we can compare our results on the same splits
set.seed(11)
#########################################
# Classification Models
########################################
# split the data into training and test data
model_data$Satisfaction <- as.factor(model_data$Satisfaction)
split = sample.split(model_data$Satisfaction, SplitRatio=.8)
training = subset(model_data, split == TRUE)
test = subset(model_data, split == FALSE)
library(e1071)
load(file="./models/best_naiveBayes.rda")
best_preds <- predict(best_model, test)
best_res <- data.frame(test, preds=best_preds)
best_res$result <- best_res$Satisfaction == best_res$preds
best_acc <- mean(best_res$result)
best_res$result <- as.factor(best_res$result)
library(ggplot2)
ggplot(best_res, aes(x=Age, y=Flight_Distance, color=preds, shape=result)) +
geom_point() +
ggtitle(paste("NaiveBayes Predictions on Test Data - Accuracy: ", round(best_acc * 100, 2) ,"%", sep=""))
ggsave("./images/best_NB_preds_Distance_Age.png")
